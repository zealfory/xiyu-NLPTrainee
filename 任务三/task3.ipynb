{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相关包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import argparse\n",
    "import zipfile\n",
    "import wget\n",
    "import time\n",
    "import pickle\n",
    "import fnmatch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset,DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### snli数据集 & 预训练词向量获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, targetdir):\n",
    "    \"\"\"下载\"\"\"\n",
    "    print(\"* Downloading data from {}...\".format(url))\n",
    "    filepath = os.path.join(targetdir, url.split('/')[-1])\n",
    "    wget.download(url, filepath)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def unzip(filepath):\n",
    "    \"\"\"解压\"\"\"\n",
    "    print(\"\\n* Extracting: {}...\".format(filepath))\n",
    "    dirpath = os.path.dirname(filepath)\n",
    "    with zipfile.ZipFile(filepath) as zf:\n",
    "        for name in zf.namelist():\n",
    "            if \"__MACOSX\" in name or\\\n",
    "               \".DS_Store\" in name or\\\n",
    "               \"Icon\" in name:\n",
    "                continue\n",
    "            zf.extract(name, dirpath)\n",
    "    os.remove(filepath)\n",
    "\n",
    "\n",
    "def download_unzip(url, targetdir):\n",
    "    filepath = os.path.join(targetdir, url.split('/')[-1])\n",
    "    target = os.path.join(targetdir,\n",
    "                          \".\".join((url.split('/')[-1]).split('.')[:-1]))\n",
    "\n",
    "    if not os.path.exists(targetdir):\n",
    "        print(\"* Creating target directory {}...\".format(targetdir))\n",
    "        os.makedirs(targetdir)\n",
    "\n",
    "    # 发现解压文件，跳过下载和解压\n",
    "    if os.path.exists(target) or os.path.exists(target + \".txt\"):\n",
    "        print(\"* Found unzipped data in {}, skipping download and unzip...\"\n",
    "              .format(targetdir))\n",
    "    # 发现压缩文件，跳过下载\n",
    "    elif os.path.exists(filepath):\n",
    "        print(\"* Found zipped data in {} - skipping download...\"\n",
    "              .format(targetdir))\n",
    "        unzip(filepath)\n",
    "    # 下载 & 解压\n",
    "    else:\n",
    "        unzip(download(url, targetdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Fetching the dataset: ==============================\n",
      "* Found unzipped data in data_task3/dataset, skipping download and unzip...\n",
      "============================== Fetching the word embeddings: ==============================\n",
      "* Found unzipped data in data_task3/embeddings, skipping download and unzip...\n"
     ]
    }
   ],
   "source": [
    "# 相应的URL\n",
    "dataset_url = \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
    "embeddings_url = \"http://www-nlp.stanford.edu/data/glove.840B.300d.zip\"\n",
    "\n",
    "target_dir = \"data_task3\"\n",
    "\n",
    "print(30*\"=\", \"Fetching the dataset:\", 30*'=')\n",
    "download_unzip(dataset_url, os.path.join(target_dir, \"dataset\"))\n",
    "\n",
    "print(30*\"=\", \"Fetching the word embeddings:\", 30*\"=\")\n",
    "download_unzip(embeddings_url, os.path.join(target_dir, \"embeddings\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据 & 词向量预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    ''' 预处理类 '''\n",
    "    def __init__(self, lowercase=False, ignore_punctuation=False, num_words=None, \n",
    "                 stopwords=[], labeldict={}, bos=None, eos=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lowercase:是否转换为小写，默认否\n",
    "            ignore_punctuation: 是否忽略标点符号，默认否\n",
    "            num_words: worddict中使用的词数量，默认None表示全部\n",
    "            stopwords: 构建worddict时的停用词表，默认为空\n",
    "            bos: 句子起始 默认None\n",
    "            eos: 句子结尾 默认None\n",
    "        \"\"\"\n",
    "        self.lowercase = lowercase\n",
    "        self.ignore_punctuation = ignore_punctuation\n",
    "        self.num_words = num_words\n",
    "        self.stopwords = stopwords\n",
    "        self.labeldict = labeldict\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "    def read_data(self, filepath):\n",
    "        \"\"\"\n",
    "        从NLI数据集读取ids，premises，hypotheses，labels，返回相应字典\n",
    "        \"\"\"\n",
    "        with open(filepath, \"r\", encoding=\"utf8\") as input_data:\n",
    "            ids, premises, hypotheses, labels = [], [], [], []\n",
    "\n",
    "            # 括号和标点符号的替换方式\n",
    "            parentheses_table = str.maketrans({\"(\": None, \")\": None})\n",
    "            punct_table = str.maketrans({key: \" \" for key in string.punctuation})\n",
    "\n",
    "            # 忽略文件首行\n",
    "            next(input_data)\n",
    "\n",
    "            # 处理每行\n",
    "            for line in input_data:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "\n",
    "                # 忽略无标签句子\n",
    "                if line[0] == \"-\":\n",
    "                    continue\n",
    "\n",
    "                pair_id = line[7] # captionID?\n",
    "                premise = line[1]\n",
    "                hypothesis = line[2]\n",
    "\n",
    "                # 移除括号\n",
    "                premise = premise.translate(parentheses_table)\n",
    "                hypothesis = hypothesis.translate(parentheses_table)\n",
    "\n",
    "                if self.lowercase:\n",
    "                    premise = premise.lower()\n",
    "                    hypothesis = hypothesis.lower()\n",
    "\n",
    "                if self.ignore_punctuation:\n",
    "                    premise = premise.translate(punct_table)\n",
    "                    hypothesis = hypothesis.translate(punct_table)\n",
    "\n",
    "                # 将句子分成词列表\n",
    "                premises.append([w for w in premise.rstrip().split()\n",
    "                                 if w not in self.stopwords])\n",
    "                hypotheses.append([w for w in hypothesis.rstrip().split()\n",
    "                                   if w not in self.stopwords])\n",
    "                labels.append(line[0])\n",
    "                ids.append(pair_id)\n",
    "\n",
    "            return {\"ids\": ids,\n",
    "                    \"premises\": premises,\n",
    "                    \"hypotheses\": hypotheses,\n",
    "                    \"labels\": labels}\n",
    "\n",
    "    def build_worddict(self, data):\n",
    "        \"\"\"\n",
    "        构建词典（词-索引）\n",
    "        Args:\n",
    "            data: read_data所返回dict\n",
    "        \"\"\"\n",
    "        words = []\n",
    "        [words.extend(sentence) for sentence in data[\"premises\"]]\n",
    "        [words.extend(sentence) for sentence in data[\"hypotheses\"]]\n",
    "\n",
    "        counts = Counter(words)\n",
    "        num_words = self.num_words\n",
    "        if self.num_words is None:\n",
    "            num_words = len(counts)\n",
    "\n",
    "        self.worddict = {}\n",
    "\n",
    "        # 索引0 -- padding\n",
    "        # 索引1 -- out-of-vocabulary words\n",
    "        # 索引2 -- beginning of sentence\n",
    "        # 索引3 -- end of sentence\n",
    "        self.worddict[\"_PAD_\"] = 0\n",
    "        self.worddict[\"_OOV_\"] = 1\n",
    "\n",
    "        offset = 2\n",
    "        if self.bos:\n",
    "            self.worddict[\"_BOS_\"] = 2\n",
    "            offset += 1\n",
    "        if self.eos:\n",
    "            self.worddict[\"_EOS_\"] = 3\n",
    "            offset += 1\n",
    "\n",
    "        for i, word in enumerate(counts.most_common(num_words)):\n",
    "            self.worddict[word[0]] = i + offset\n",
    "\n",
    "        if self.labeldict == {}:\n",
    "            label_names = set(data[\"labels\"])\n",
    "            self.labeldict = {label_name: i\n",
    "                              for i, label_name in enumerate(label_names)}\n",
    "\n",
    "    def words_to_indices(self, sentence):\n",
    "        \"\"\"\n",
    "        将句子中词转换为词典中对应的索引\n",
    "        Args:\n",
    "            sentence: 词列表\n",
    "        Returns:\n",
    "            索引列表\n",
    "        \"\"\"\n",
    "        indices = []\n",
    "\n",
    "        # BOS\n",
    "        if self.bos:\n",
    "            indices.append(self.worddict[\"_BOS_\"])\n",
    "\n",
    "        for word in sentence:\n",
    "            if word in self.worddict:\n",
    "                index = self.worddict[word]\n",
    "            else:\n",
    "\n",
    "                # out-of-vocabulary word (OOV).\n",
    "                index = self.worddict[\"_OOV_\"]\n",
    "            indices.append(index)\n",
    "\n",
    "        # EOS\n",
    "        if self.eos:\n",
    "            indices.append(self.worddict[\"_EOS_\"])\n",
    "\n",
    "        return indices\n",
    "\n",
    "    def indices_to_words(self, indices):\n",
    "        \"\"\"\n",
    "        将索引转换为词\n",
    "        \"\"\"\n",
    "        return [list(self.worddict.keys())[list(self.worddict.values())\n",
    "                                           .index(i)]\n",
    "                for i in indices]\n",
    "\n",
    "    def transform_to_indices(self, data):\n",
    "        \"\"\"\n",
    "        将premises和hypotheses，labels转换为索引\n",
    "        Args:\n",
    "            data: read_data返回的dict\n",
    "        Returns:\n",
    "            包含转换后premises, hypotheses,labels的dict.\n",
    "        \"\"\"\n",
    "        transformed_data = {\"ids\": [],\n",
    "                            \"premises\": [],\n",
    "                            \"hypotheses\": [],\n",
    "                            \"labels\": []}\n",
    "\n",
    "        for i, premise in enumerate(data[\"premises\"]):\n",
    "            # Ignore sentences that have a label for which no index was\n",
    "            # defined in 'labeldict'.\n",
    "            label = data[\"labels\"][i]\n",
    "            if label not in self.labeldict and label != \"hidden\":\n",
    "                continue\n",
    "\n",
    "            transformed_data[\"ids\"].append(data[\"ids\"][i])\n",
    "\n",
    "            if label == \"hidden\":\n",
    "                transformed_data[\"labels\"].append(-1)\n",
    "            else:\n",
    "                transformed_data[\"labels\"].append(self.labeldict[label])\n",
    "\n",
    "            indices = self.words_to_indices(premise)\n",
    "            transformed_data[\"premises\"].append(indices)\n",
    "\n",
    "            indices = self.words_to_indices(data[\"hypotheses\"][i])\n",
    "            transformed_data[\"hypotheses\"].append(indices)\n",
    "\n",
    "        return transformed_data\n",
    "\n",
    "    def build_embedding_matrix(self, embeddings_file):\n",
    "        \"\"\"\n",
    "        为当前词典创建预训练词向量矩阵\n",
    "        Args:\n",
    "            embeddings_file: 预训练词向量\n",
    "        Returns:\n",
    "            numpy矩阵 -- 大小(num_words + n_special_tokens, embedding_dim)\n",
    "            n_special_tokens: padding/oov/bos/eos\n",
    "        \"\"\"\n",
    "        # 加载词向量\n",
    "        embeddings = {}\n",
    "        with open(embeddings_file, \"r\", encoding=\"utf8\") as input_data:\n",
    "            for line in input_data:\n",
    "                line = line.split()\n",
    "\n",
    "                try:\n",
    "                    # 检查是否为词向量数据\n",
    "                    float(line[1])\n",
    "                    word = line[0]\n",
    "                    if word in self.worddict:\n",
    "                        embeddings[word] = line[1:]\n",
    "\n",
    "                # 忽略无用行\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "        num_words = len(self.worddict)\n",
    "        embedding_dim = len(list(embeddings.values())[0])\n",
    "        embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "        # 构建矩阵\n",
    "        missed = 0\n",
    "        for word, i in self.worddict.items():\n",
    "            if word in embeddings:\n",
    "                embedding_matrix[i] = np.array(embeddings[word], dtype=float)\n",
    "            else:\n",
    "                if word == \"_PAD_\":\n",
    "                    continue\n",
    "                missed += 1\n",
    "                # oov词高斯随机初始化\n",
    "                embedding_matrix[i] = np.random.normal(size=(embedding_dim))\n",
    "        print(\"Missed words: \", missed)\n",
    "\n",
    "        return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_SNLI_data(inputdir, embeddings_file, targetdir, lowercase=False, ignore_punctuation=False,\n",
    "                         num_words=None, stopwords=[], labeldict={}, bos=None, eos=None):\n",
    "\n",
    "    if not os.path.exists(targetdir):\n",
    "        os.makedirs(targetdir)\n",
    "\n",
    "    # 获取训练，验证，测试文件\n",
    "    train_file = \"\"\n",
    "    dev_file = \"\"\n",
    "    test_file = \"\"\n",
    "    for file in os.listdir(inputdir):\n",
    "        if fnmatch.fnmatch(file, \"*_train.txt\"):\n",
    "            train_file = file\n",
    "        elif fnmatch.fnmatch(file, \"*_dev.txt\"):\n",
    "            dev_file = file\n",
    "        elif fnmatch.fnmatch(file, \"*_test.txt\"):\n",
    "            test_file = file\n",
    "\n",
    "    # ------------------------- 训练数据集预处理 -------------------------- #\n",
    "    preprocessor = Preprocessor(lowercase=lowercase, ignore_punctuation=ignore_punctuation,\n",
    "                                num_words=num_words, stopwords=stopwords,\n",
    "                                labeldict=labeldict, bos=bos, eos=eos)\n",
    "\n",
    "    print(30*\"=\", \" Preprocessing train set \", 30*\"=\")\n",
    "    print(\"\\t* Reading data...\")\n",
    "    data = preprocessor.read_data(os.path.join(inputdir, train_file))\n",
    "\n",
    "    print(\"\\t* Computing worddict and saving it...\")\n",
    "    preprocessor.build_worddict(data)\n",
    "    with open(os.path.join(targetdir, \"worddict.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(preprocessor.worddict, pkl_file)\n",
    "\n",
    "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
    "    transformed_data = preprocessor.transform_to_indices(data)\n",
    "    print(\"\\t* Saving result...\")\n",
    "    with open(os.path.join(targetdir, \"train_data.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(transformed_data, pkl_file)\n",
    "\n",
    "    # ------------------------ 验证数据集预处理 --------------------------- #\n",
    "    print(30*\"=\", \" Preprocessing dev set \", 30*\"=\")\n",
    "    print(\"\\t* Reading data...\")\n",
    "    data = preprocessor.read_data(os.path.join(inputdir, dev_file))\n",
    "\n",
    "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
    "    transformed_data = preprocessor.transform_to_indices(data)\n",
    "    print(\"\\t* Saving result...\")\n",
    "    with open(os.path.join(targetdir, \"dev_data.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(transformed_data, pkl_file)\n",
    "\n",
    "    # ------------------------ 测试数据集预处理 --------------------------- #\n",
    "    print(30*\"=\", \" Preprocessing test set \", 30*\"=\")\n",
    "    print(\"\\t* Reading data...\")\n",
    "    data = preprocessor.read_data(os.path.join(inputdir, test_file))\n",
    "\n",
    "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
    "    transformed_data = preprocessor.transform_to_indices(data)\n",
    "    print(\"\\t* Saving result...\")\n",
    "    with open(os.path.join(targetdir, \"test_data.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(transformed_data, pkl_file)\n",
    "\n",
    "    # ------------------------ 词向量预处理 ----------------------------- #\n",
    "    print(30*\"=\", \" Preprocessing embeddings \", 30*\"=\")\n",
    "    print(\"\\t* Building embedding matrix and saving it...\")\n",
    "    embed_matrix = preprocessor.build_embedding_matrix(embeddings_file)\n",
    "    with open(os.path.join(targetdir, \"embeddings.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(embed_matrix, pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Preprocessing train set  ====================\n",
      "\t* Reading data...\n",
      "\t* Computing worddict and saving it...\n",
      "\t* Transforming words in premises and hypotheses to indices...\n",
      "\t* Saving result...\n",
      "====================  Preprocessing dev set  ====================\n",
      "\t* Reading data...\n",
      "\t* Transforming words in premises and hypotheses to indices...\n",
      "\t* Saving result...\n",
      "====================  Preprocessing test set  ====================\n",
      "\t* Reading data...\n",
      "\t* Transforming words in premises and hypotheses to indices...\n",
      "\t* Saving result...\n",
      "====================  Preprocessing embeddings  ====================\n",
      "\t* Building embedding matrix and saving it...\n",
      "Missed words:  4045\n"
     ]
    }
   ],
   "source": [
    "default_config = \"config/snli_preprocessing.json\" # 配置文件\n",
    "\n",
    "with open(default_config, \"r\") as cfg_file:\n",
    "    config = json.load(cfg_file)\n",
    "\n",
    "### 数据预处理 \n",
    "preprocess_SNLI_data(\n",
    "    os.path.normpath(config[\"data_dir\"]), # \"data_task3/dataset/snli_1.0\"\n",
    "    os.path.normpath(config[\"embeddings_file\"]), # \"data_task3/embeddings/glove.840B.300d.txt\",\n",
    "    os.path.normpath(config[\"target_dir\"]), # \"data_task3/preprocessed/SNLI\"\n",
    "    lowercase=config[\"lowercase\"], # false\n",
    "    ignore_punctuation=config[\"ignore_punctuation\"], # false\n",
    "    num_words=config[\"num_words\"], # None\n",
    "    stopwords=config[\"stopwords\"], # []\n",
    "    labeldict=config[\"labeldict\"], # {'e':0, 'n':1, 'c':2}\n",
    "    bos=config[\"bos\"], # '_BOS_'\n",
    "    eos=config[\"eos\"] # '_EOS_'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据加载类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, padding_idx=0, max_premise_length=None,\n",
    "                 max_hypothesis_length=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: 包含预处理premises, hypotheses 和 labels的字典.\n",
    "            padding_idx: 用于padding的索引, 默认0.\n",
    "            max_premise_length: premises的最大长度. 默认None，使用data中premises最大长度.\n",
    "            max_hypothesis_length: hypotheses的最大长度. 默认None，使用data中hypotheses最大长度.\n",
    "        \"\"\"\n",
    "        self.premises_lengths = [len(seq) for seq in data[\"premises\"]]\n",
    "        self.max_premise_length = max_premise_length\n",
    "        if self.max_premise_length is None:\n",
    "            self.max_premise_length = max(self.premises_lengths)\n",
    "\n",
    "        self.hypotheses_lengths = [len(seq) for seq in data[\"hypotheses\"]]\n",
    "        self.max_hypothesis_length = max_hypothesis_length\n",
    "        if self.max_hypothesis_length is None:\n",
    "            self.max_hypothesis_length = max(self.hypotheses_lengths)\n",
    "\n",
    "        self.num_sequences = len(data[\"premises\"])\n",
    "\n",
    "        self.data = {\"ids\": [],\n",
    "                     \"premises\": torch.ones((self.num_sequences,\n",
    "                                             self.max_premise_length),\n",
    "                                            dtype=torch.long) * padding_idx,\n",
    "                     \"hypotheses\": torch.ones((self.num_sequences,\n",
    "                                               self.max_hypothesis_length),\n",
    "                                              dtype=torch.long) * padding_idx,\n",
    "                     \"labels\": torch.tensor(data[\"labels\"], dtype=torch.long)}\n",
    "\n",
    "        for i, premise in enumerate(data[\"premises\"]):\n",
    "            self.data[\"ids\"].append(data[\"ids\"][i])\n",
    "            end = min(len(premise), self.max_premise_length)\n",
    "            self.data[\"premises\"][i][:end] = torch.tensor(premise[:end])\n",
    "\n",
    "            hypothesis = data[\"hypotheses\"][i]\n",
    "            end = min(len(hypothesis), self.max_hypothesis_length)\n",
    "            self.data[\"hypotheses\"][i][:end] = torch.tensor(hypothesis[:end])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sequences\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\"id\": self.data[\"ids\"][index],\n",
    "                \"premise\": self.data[\"premises\"][index],\n",
    "                \"premise_length\": min(self.premises_lengths[index],\n",
    "                                      self.max_premise_length),\n",
    "                \"hypothesis\": self.data[\"hypotheses\"][index],\n",
    "                \"hypothesis_length\": min(self.hypotheses_lengths[index],\n",
    "                                         self.max_hypothesis_length),\n",
    "                \"label\": self.data[\"labels\"][index]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 工具函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ESIM model的工具函数\n",
    "\"\"\"\n",
    "\n",
    "def sort_by_seq_lens(batch, sequences_lengths, descending=True):\n",
    "    \"\"\"\n",
    "    按句子长度排序，防止padding夹在中间\n",
    "    Args:\n",
    "        batch: 批，大小(batch_size ，max_sequence_length ，*)\n",
    "        sequences_lengths: 句子长度，大小 (batch_size).\n",
    "        descending: 是否降序\n",
    "\n",
    "    \"\"\"\n",
    "    sorted_seq_lens, sorting_index = sequences_lengths.sort(0, descending=descending)\n",
    "\n",
    "    sorted_batch = batch.index_select(0, sorting_index)\n",
    "\n",
    "    idx_range = sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n",
    "    \n",
    "    _, reverse_mapping = sorting_index.sort(0, descending=False)\n",
    "    restoration_index = idx_range.index_select(0, reverse_mapping)\n",
    "\n",
    "    return sorted_batch, sorted_seq_lens, sorting_index, restoration_index\n",
    "\n",
    "\n",
    "def get_mask(sequences_batch, sequences_lengths):\n",
    "    \"\"\"\n",
    "    得到mask矩阵\n",
    "    \"\"\"\n",
    "    batch_size = sequences_batch.size()[0]\n",
    "    max_length = torch.max(sequences_lengths)\n",
    "    mask = torch.ones(batch_size, max_length, dtype=torch.float)\n",
    "    mask[sequences_batch[:, :max_length] == 0] = 0.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def masked_softmax(tensor, mask):\n",
    "    \"\"\"\n",
    "    masked softmax 大小(batch, *, sequence_length)\n",
    "    \"\"\"\n",
    "    tensor_shape = tensor.size()\n",
    "    reshaped_tensor = tensor.view(-1, tensor_shape[-1])\n",
    "\n",
    "    while mask.dim() < tensor.dim():\n",
    "        mask = mask.unsqueeze(1)\n",
    "    mask = mask.expand_as(tensor).contiguous().float()\n",
    "    reshaped_mask = mask.view(-1, mask.size()[-1])\n",
    "\n",
    "    result = nn.functional.softmax(reshaped_tensor * reshaped_mask, dim=-1)\n",
    "    result = result * reshaped_mask\n",
    "    # 1e-13 is added to avoid divisions by zero.\n",
    "    result = result / (result.sum(dim=-1, keepdim=True) + 1e-13)\n",
    "\n",
    "    return result.view(*tensor_shape)\n",
    "\n",
    "def weighted_sum(tensor, weights, mask):\n",
    "    \"\"\"\n",
    "    Apply a weighted sum on the vectors along the last dimension of 'tensor',\n",
    "    and mask the vectors in the result with 'mask'.\n",
    "    Args:\n",
    "        tensor: A tensor of vectors on which a weighted sum must be applied.\n",
    "        weights: The weights to use in the weighted sum.\n",
    "        mask: A mask to apply on the result of the weighted sum.\n",
    "    Returns:\n",
    "        A new tensor containing the result of the weighted sum after the mask\n",
    "        has been applied on it.\n",
    "    \"\"\"\n",
    "    weighted_sum = weights.bmm(tensor)\n",
    "\n",
    "    while mask.dim() < weighted_sum.dim():\n",
    "        mask = mask.unsqueeze(1)\n",
    "    mask = mask.transpose(-1, -2)\n",
    "    mask = mask.expand_as(weighted_sum).contiguous().float()\n",
    "\n",
    "    return weighted_sum * mask\n",
    "\n",
    "def replace_masked(tensor, mask, value):\n",
    "    \"\"\"\n",
    "    Replace the all the values of vectors in 'tensor' that are masked in\n",
    "    'masked' by 'value'.\n",
    "    Args:\n",
    "        tensor: The tensor in which the masked vectors must have their values\n",
    "            replaced.\n",
    "        mask: A mask indicating the vectors which must have their values\n",
    "            replaced.\n",
    "        value: The value to place in the masked vectors of 'tensor'.\n",
    "    Returns:\n",
    "        A new tensor of the same size as 'tensor' where the values of the\n",
    "        vectors masked in 'mask' were replaced by 'value'.\n",
    "    \"\"\"\n",
    "    mask = mask.unsqueeze(1).transpose(2, 1)\n",
    "    reverse_mask = 1.0 - mask\n",
    "    values_to_add = value * reverse_mask\n",
    "    return tensor * mask + values_to_add\n",
    "\n",
    "\n",
    "def correct_predictions(output_probabilities, targets):\n",
    "    \"\"\"\n",
    "    计算准确预测的个数\n",
    "    \"\"\"\n",
    "    _, out_classes = output_probabilities.max(dim=1)\n",
    "    correct = (out_classes == targets).sum()\n",
    "    return correct.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESIM结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention层 \n",
    "    输入RNN输出的premise和hypothesis\n",
    "    计算点积 softmax 作为权重\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, premise_batch, premise_mask, hypothesis_batch, hypothesis_mask):\n",
    "\n",
    "        # 求点积\n",
    "        similarity_matrix = premise_batch.bmm(hypothesis_batch.transpose(2, 1)\n",
    "                                                              .contiguous())\n",
    "\n",
    "        # Softmax attention权重\n",
    "        prem_hyp_attn = masked_softmax(similarity_matrix, hypothesis_mask)\n",
    "        hyp_prem_attn = masked_softmax(similarity_matrix.transpose(1, 2)\n",
    "                                                        .contiguous(),\n",
    "                                       premise_mask)\n",
    "\n",
    "        # 加权求和\n",
    "        attended_premises = weighted_sum(hypothesis_batch,\n",
    "                                         prem_hyp_attn,\n",
    "                                         premise_mask)\n",
    "        attended_hypotheses = weighted_sum(premise_batch,\n",
    "                                           hyp_prem_attn,\n",
    "                                           hypothesis_mask)\n",
    "\n",
    "        return attended_premises, attended_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, input_size, hidden_size,\n",
    "                 num_layers=1, bias=True, dropout=0.0, bidirectional=False):\n",
    " \n",
    "        assert issubclass(rnn_type, nn.RNNBase),\\\n",
    "            \"rnn_type must be a class inheriting from torch.nn.RNNBase\"\n",
    "\n",
    "        super(Seq2SeqEncoder, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self._encoder = rnn_type(input_size,\n",
    "                                 hidden_size,\n",
    "                                 num_layers=num_layers,\n",
    "                                 bias=bias,\n",
    "                                 batch_first=True,\n",
    "                                 dropout=dropout,\n",
    "                                 bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, sequences_batch, sequences_lengths):\n",
    "\n",
    "        sorted_batch, sorted_lengths, _, restoration_idx = sort_by_seq_lens(sequences_batch, sequences_lengths)\n",
    "        \n",
    "        # pack\n",
    "        packed_batch = nn.utils.rnn.pack_padded_sequence(sorted_batch,\n",
    "                                                         sorted_lengths,\n",
    "                                                         batch_first=True)\n",
    "\n",
    "        outputs, _ = self._encoder(packed_batch, None)\n",
    "        \n",
    "        # pad\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs,\n",
    "                                                      batch_first=True)\n",
    "        reordered_outputs = outputs.index_select(0, restoration_idx)\n",
    "\n",
    "        return reordered_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_esim_weights(module):\n",
    "    \"\"\"\n",
    "    初始化ESIM参数\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight.data)\n",
    "        nn.init.constant_(module.bias.data, 0.0)\n",
    "\n",
    "    elif isinstance(module, nn.LSTM):\n",
    "        nn.init.xavier_uniform_(module.weight_ih_l0.data)\n",
    "        nn.init.orthogonal_(module.weight_hh_l0.data)\n",
    "        nn.init.constant_(module.bias_ih_l0.data, 0.0)\n",
    "        nn.init.constant_(module.bias_hh_l0.data, 0.0)\n",
    "        hidden_size = module.bias_hh_l0.data.shape[0] // 4\n",
    "        module.bias_hh_l0.data[hidden_size:(2*hidden_size)] = 1.0\n",
    "\n",
    "        if (module.bidirectional):\n",
    "            nn.init.xavier_uniform_(module.weight_ih_l0_reverse.data)\n",
    "            nn.init.orthogonal_(module.weight_hh_l0_reverse.data)\n",
    "            nn.init.constant_(module.bias_ih_l0_reverse.data, 0.0)\n",
    "            nn.init.constant_(module.bias_hh_l0_reverse.data, 0.0)\n",
    "            module.bias_hh_l0_reverse.data[hidden_size:(2*hidden_size)] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESIM(nn.Module):\n",
    "    \"\"\"\n",
    "    ESIM model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, embeddings=None,\n",
    "                 padding_idx=0, dropout=0.5, num_classes=3, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: 词表大小\n",
    "            embedding_dim: 词向量维度\n",
    "            hidden_size: 隐藏层大小\n",
    "            embeddings: 词向量，大小为(vocab_size, embedding_dim)，默认None表示随机初始化\n",
    "            padding_idx: padding index，默认0\n",
    "            dropout: dropout rate，默认0.5\n",
    "            num_classes: 输出类别数，默认为3:E/N/C\n",
    "            device: model运行的设备，默认cpu\n",
    "        \"\"\"\n",
    "        super(ESIM, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        # Embedding layer\n",
    "        self._word_embedding = nn.Embedding(self.vocab_size,\n",
    "                                            self.embedding_dim,\n",
    "                                            padding_idx=padding_idx,\n",
    "                                            _weight=embeddings)\n",
    "        # Dropout\n",
    "        if self.dropout:\n",
    "            self._rnn_dropout = nn.Dropout(p=self.dropout)\n",
    "        \n",
    "        # biLSTM\n",
    "        self._encoding = Seq2SeqEncoder(nn.LSTM,\n",
    "                                        self.embedding_dim,\n",
    "                                        self.hidden_size,\n",
    "                                        bidirectional=True)\n",
    "        \n",
    "        # Attention\n",
    "        self._attention = SoftmaxAttention()\n",
    "\n",
    "        # Projection\n",
    "        self._projection = nn.Sequential(nn.Linear(4*2*self.hidden_size,\n",
    "                                                   self.hidden_size),\n",
    "                                         nn.ReLU())\n",
    "        \n",
    "        # biLSTM\n",
    "        self._composition = Seq2SeqEncoder(nn.LSTM,\n",
    "                                           self.hidden_size,\n",
    "                                           self.hidden_size,\n",
    "                                           bidirectional=True)\n",
    "        # Prediction\n",
    "        self._classification = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                             nn.Linear(2*4*self.hidden_size,\n",
    "                                                       self.hidden_size),\n",
    "                                             nn.Tanh(),\n",
    "                                             nn.Dropout(p=self.dropout),\n",
    "                                             nn.Linear(self.hidden_size,\n",
    "                                                       self.num_classes))\n",
    "\n",
    "        # Initialization\n",
    "        self.apply(_init_esim_weights)\n",
    "\n",
    "    def forward(self, premises, premises_lengths, hypotheses, hypotheses_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            premises: (batch, premises_length).\n",
    "            premises_lengths: 'premises'中句子的长度.\n",
    "            hypothesis: A batch of varaible length sequences of word indices\n",
    "                representing hypotheses. The batch is assumed to be of size\n",
    "                (batch, hypotheses_length).\n",
    "            hypotheses_lengths: A 1D tensor containing the lengths of the\n",
    "                hypotheses in 'hypotheses'.\n",
    "        Returns:\n",
    "            logits: A tensor of size (batch, num_classes) containing the\n",
    "                logits for each output class of the model.\n",
    "            probabilities: A tensor of size (batch, num_classes) containing\n",
    "                the probabilities of each output class in the model.\n",
    "        \"\"\"\n",
    "        premises_mask = get_mask(premises, premises_lengths).to(self.device)\n",
    "        hypotheses_mask = get_mask(hypotheses, hypotheses_lengths).to(self.device)\n",
    "\n",
    "        # =========================== Input Encoding ============================\n",
    "\n",
    "        embedded_premises = self._word_embedding(premises)\n",
    "        embedded_hypotheses = self._word_embedding(hypotheses)\n",
    "\n",
    "        if self.dropout:\n",
    "            embedded_premises = self._rnn_dropout(embedded_premises)\n",
    "            embedded_hypotheses = self._rnn_dropout(embedded_hypotheses)\n",
    "\n",
    "        encoded_premises = self._encoding(embedded_premises,\n",
    "                                          premises_lengths)\n",
    "        encoded_hypotheses = self._encoding(embedded_hypotheses,\n",
    "                                            hypotheses_lengths)\n",
    "        \n",
    "        # ========================== Local inference modeling =====================\n",
    "\n",
    "        attended_premises, attended_hypotheses =\\\n",
    "            self._attention(encoded_premises, premises_mask,\n",
    "                            encoded_hypotheses, hypotheses_mask)\n",
    "\n",
    "        enhanced_premises = torch.cat([encoded_premises,\n",
    "                                       attended_premises,\n",
    "                                       encoded_premises - attended_premises,\n",
    "                                       encoded_premises * attended_premises],\n",
    "                                      dim=-1)\n",
    "        enhanced_hypotheses = torch.cat([encoded_hypotheses,\n",
    "                                         attended_hypotheses,\n",
    "                                         encoded_hypotheses -\n",
    "                                         attended_hypotheses,\n",
    "                                         encoded_hypotheses *\n",
    "                                         attended_hypotheses],\n",
    "                                        dim=-1)\n",
    "        \n",
    "        # ========================== inference composition ========================\n",
    "\n",
    "        projected_premises = self._projection(enhanced_premises)\n",
    "        projected_hypotheses = self._projection(enhanced_hypotheses)\n",
    "\n",
    "        if self.dropout:\n",
    "            projected_premises = self._rnn_dropout(projected_premises)\n",
    "            projected_hypotheses = self._rnn_dropout(projected_hypotheses)\n",
    "\n",
    "        v_ai = self._composition(projected_premises, premises_lengths)\n",
    "        v_bj = self._composition(projected_hypotheses, hypotheses_lengths)\n",
    "\n",
    "        v_a_avg = torch.sum(v_ai * premises_mask.unsqueeze(1)\n",
    "                                                .transpose(2, 1), dim=1)\\\n",
    "            / torch.sum(premises_mask, dim=1, keepdim=True)\n",
    "        v_b_avg = torch.sum(v_bj * hypotheses_mask.unsqueeze(1)\n",
    "                                                  .transpose(2, 1), dim=1)\\\n",
    "            / torch.sum(hypotheses_mask, dim=1, keepdim=True)\n",
    "\n",
    "        v_a_max, _ = replace_masked(v_ai, premises_mask, -1e7).max(dim=1)\n",
    "        v_b_max, _ = replace_masked(v_bj, hypotheses_mask, -1e7).max(dim=1)\n",
    "\n",
    "        v = torch.cat([v_a_avg, v_a_max, v_b_avg, v_b_max], dim=1)\n",
    "\n",
    "        logits = self._classification(v)\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        return logits, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练 & 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer,\n",
    "          criterion, epoch_number, max_gradient_norm):\n",
    "    \"\"\"\n",
    "    训练\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    device = model.device\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    batch_time_avg = 0.0\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "\n",
    "    tqdm_batch_iterator = tqdm(dataloader)\n",
    "    for batch_index, batch in enumerate(tqdm_batch_iterator):\n",
    "        batch_start = time.time()\n",
    "\n",
    "        premises = batch[\"premise\"].to(device)\n",
    "        premises_lengths = batch[\"premise_length\"].to(device)\n",
    "        hypotheses = batch[\"hypothesis\"].to(device)\n",
    "        hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, probs = model(premises,\n",
    "                              premises_lengths,\n",
    "                              hypotheses,\n",
    "                              hypotheses_lengths)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time_avg += time.time() - batch_start\n",
    "        running_loss += loss.item()\n",
    "        correct_preds += correct_predictions(probs, labels)\n",
    "\n",
    "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
    "                      .format(batch_time_avg/(batch_index+1),\n",
    "                              running_loss/(batch_index+1))\n",
    "        tqdm_batch_iterator.set_description(description)\n",
    "        \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_preds / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_time, epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    验证\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            premises = batch[\"premise\"].to(device)\n",
    "            premises_lengths = batch[\"premise_length\"].to(device)\n",
    "            hypotheses = batch[\"hypothesis\"].to(device)\n",
    "            hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits, probs = model(premises,\n",
    "                                  premises_lengths,\n",
    "                                  hypotheses,\n",
    "                                  hypotheses_lengths)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += correct_predictions(probs, labels)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = running_accuracy / (len(dataloader.dataset))\n",
    "\n",
    "    return epoch_time, epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "在处理过的snli数据集上进行训练\n",
    "\"\"\"\n",
    "def main(train_file, valid_file, embeddings_file, target_dir, hidden_size=300,\n",
    "         dropout=0.5, num_classes=3, epochs=64, batch_size=32, lr=0.0004,\n",
    "         patience=5, max_grad_norm=10.0, checkpoint=None):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(30 * \"=\", \" Preparing for training \", 30 * \"=\")\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # -------------------- 数据加载 ------------------- #\n",
    "    print(\"\\t* Loading training data...\")\n",
    "    with open(train_file, \"rb\") as pkl:\n",
    "        train_data = NLIDataset(pickle.load(pkl))\n",
    "\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    print(\"\\t* Loading validation data...\")\n",
    "    with open(valid_file, \"rb\") as pkl:\n",
    "        valid_data = NLIDataset(pickle.load(pkl))\n",
    "\n",
    "    valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # -------------------- 模型构建 ------------------- #\n",
    "    print(\"\\t* Building model...\")\n",
    "    with open(embeddings_file, \"rb\") as pkl:\n",
    "        embeddings = torch.tensor(pickle.load(pkl), dtype=torch.float)\\\n",
    "                     .to(device)\n",
    "\n",
    "    model = ESIM(embeddings.shape[0],\n",
    "                 embeddings.shape[1],\n",
    "                 hidden_size,\n",
    "                 embeddings=embeddings,\n",
    "                 dropout=dropout,\n",
    "                 num_classes=num_classes,\n",
    "                 device=device).to(device)\n",
    "\n",
    "    # -------------------- 准备训练  ------------------- #\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                           mode=\"max\",\n",
    "                                                           factor=0.5,\n",
    "                                                           patience=0)\n",
    "\n",
    "    best_score = 0.0\n",
    "    start_epoch = 1\n",
    "\n",
    "    # 损失曲线数据list\n",
    "    epochs_count = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # 从给定checkpoint继续训练\n",
    "    if checkpoint:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_score = checkpoint[\"best_score\"]\n",
    "\n",
    "        print(\"\\t* Training will continue on existing model from epoch {}...\"\n",
    "              .format(start_epoch))\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        epochs_count = checkpoint[\"epochs_count\"]\n",
    "        train_losses = checkpoint[\"train_losses\"]\n",
    "        valid_losses = checkpoint[\"valid_losses\"]\n",
    "\n",
    "    # 计算训练开始前的损失和精度\n",
    "    _, valid_loss, valid_accuracy = validate(model,\n",
    "                                             valid_loader,\n",
    "                                             criterion)\n",
    "    print(\"\\t* Validation loss before training: {:.4f}, accuracy: {:.4f}%\"\n",
    "          .format(valid_loss, (valid_accuracy*100)))\n",
    "\n",
    "    # -------------------- 迭代 ------------------- #\n",
    "    print(\"\\n\", 30 * \"=\",\"Training ESIM model on device: {}\".format(device),\n",
    "          30 * \"=\")\n",
    "\n",
    "    patience_counter = 0\n",
    "    for epoch in range(start_epoch, epochs+1):\n",
    "        epochs_count.append(epoch)\n",
    "\n",
    "        print(\"* Training epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss, epoch_accuracy = train(model,\n",
    "                                                       train_loader,\n",
    "                                                       optimizer,\n",
    "                                                       criterion,\n",
    "                                                       epoch,\n",
    "                                                       max_grad_norm)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\"\n",
    "              .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
    "\n",
    "        print(\"* Validation for epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss, epoch_accuracy = validate(model,\n",
    "                                                          valid_loader,\n",
    "                                                          criterion)\n",
    "\n",
    "        valid_losses.append(epoch_loss)\n",
    "        print(\"-> Valid. time: {:.4f}s, loss: {:.4f}, accuracy: {:.4f}%\\n\"\n",
    "              .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step(epoch_accuracy)\n",
    "\n",
    "        # Early stopping on validation accuracy.\n",
    "        if epoch_accuracy < best_score:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            best_score = epoch_accuracy\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # 保存最优模型\n",
    "            torch.save({\"epoch\": epoch,\n",
    "                        \"model\": model.state_dict(),\n",
    "                        \"best_score\": best_score,\n",
    "                        \"epochs_count\": epochs_count,\n",
    "                        \"train_losses\": train_losses,\n",
    "                        \"valid_losses\": valid_losses},\n",
    "                       os.path.join(target_dir, \"best.pth.tar\"))\n",
    "\n",
    "        # 每轮保存模型\n",
    "        torch.save({\"epoch\": epoch,\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"best_score\": best_score,\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"epochs_count\": epochs_count,\n",
    "                    \"train_losses\": train_losses,\n",
    "                    \"valid_losses\": valid_losses},\n",
    "                   os.path.join(target_dir, \"esim_{}.pth.tar\".format(epoch)))\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "            break\n",
    "\n",
    "    # 损失曲线\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_count, train_losses, \"-r\")\n",
    "    plt.plot(epochs_count, valid_losses, \"-b\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "    plt.title(\"Cross entropy loss\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Preparing for training  ====================\n",
      "\t* Loading training data...\n",
      "\t* Loading validation data...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "Avg. batch proc. time: 0.0517s, loss: 1.1366:   0%|          | 2/17168 [00:00<20:01, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 1.0979, accuracy: 33.1030%\n",
      "\n",
      " ==================== Training ESIM model on device: cuda:0 ====================\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0512s, loss: 0.6506: 100%|██████████| 17168/17168 [15:25<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 925.8028s, loss = 0.6506, accuracy: 72.6707%\n",
      "* Validation for epoch 1:\n",
      "-> Valid. time: 3.4318s, loss: 0.4428, accuracy: 83.0217%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0478s, loss: 0.4247:   0%|          | 2/17168 [00:00<17:55, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0489s, loss: 0.4869: 100%|██████████| 17168/17168 [14:43<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 883.1345s, loss = 0.4869, accuracy: 81.0739%\n",
      "* Validation for epoch 2:\n",
      "-> Valid. time: 3.5365s, loss: 0.3900, accuracy: 84.9929%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0487s, loss: 0.4054:   0%|          | 2/17168 [00:00<18:49, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0522s, loss: 0.4404: 100%|██████████| 17168/17168 [15:42<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 942.9153s, loss = 0.4404, accuracy: 83.1805%\n",
      "* Validation for epoch 3:\n",
      "-> Valid. time: 3.3643s, loss: 0.3682, accuracy: 86.1004%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0451s, loss: 0.4260:   0%|          | 2/17168 [00:00<17:20, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0475s, loss: 0.4118: 100%|██████████| 17168/17168 [14:16<00:00, 20.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 856.2201s, loss = 0.4118, accuracy: 84.4439%\n",
      "* Validation for epoch 4:\n",
      "-> Valid. time: 3.4008s, loss: 0.3607, accuracy: 86.7710%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0478s, loss: 0.5995:   0%|          | 2/17168 [00:00<17:57, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0556s, loss: 0.3929: 100%|██████████| 17168/17168 [16:42<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1002.5916s, loss = 0.3929, accuracy: 85.2940%\n",
      "* Validation for epoch 5:\n",
      "-> Valid. time: 3.4373s, loss: 0.3489, accuracy: 87.1368%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0521s, loss: 0.2345:   0%|          | 2/17168 [00:00<19:12, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0575s, loss: 0.3783: 100%|██████████| 17168/17168 [17:14<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1034.4365s, loss = 0.3783, accuracy: 85.9375%\n",
      "* Validation for epoch 6:\n",
      "-> Valid. time: 3.4364s, loss: 0.3547, accuracy: 87.3603%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0470s, loss: 0.3040:   0%|          | 2/17168 [00:00<18:12, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0487s, loss: 0.3658: 100%|██████████| 17168/17168 [14:36<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 876.0709s, loss = 0.3658, accuracy: 86.4298%\n",
      "* Validation for epoch 7:\n",
      "-> Valid. time: 3.4682s, loss: 0.3511, accuracy: 87.0555%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0463s, loss: 0.3573:   0%|          | 2/17168 [00:00<18:30, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0526s, loss: 0.3420: 100%|██████████| 17168/17168 [15:47<00:00, 17.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 947.1578s, loss = 0.3420, accuracy: 87.4477%\n",
      "* Validation for epoch 8:\n",
      "-> Valid. time: 3.4486s, loss: 0.3399, accuracy: 87.5533%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0479s, loss: 0.4744:   0%|          | 2/17168 [00:00<18:08, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0532s, loss: 0.3312: 100%|██████████| 17168/17168 [15:58<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 958.0141s, loss = 0.3312, accuracy: 87.8957%\n",
      "* Validation for epoch 9:\n",
      "-> Valid. time: 3.5238s, loss: 0.3382, accuracy: 87.7870%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0467s, loss: 0.2813:   0%|          | 2/17168 [00:00<17:48, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0534s, loss: 0.3212:  58%|█████▊    | 9948/17168 [09:17<07:35, 15.87it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Avg. batch proc. time: 0.0534s, loss: 0.3220: 100%|██████████| 17168/17168 [16:01<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 961.6855s, loss = 0.3220, accuracy: 88.2661%\n",
      "* Validation for epoch 10:\n",
      "-> Valid. time: 3.5200s, loss: 0.3390, accuracy: 87.5940%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_config = \"config/snli_training.json\" # 训练的配置文件\n",
    "with open(default_config, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "    main(os.path.normpath(config[\"train_data\"]),\n",
    "         os.path.normpath(config[\"valid_data\"]),\n",
    "         os.path.normpath(config[\"embeddings\"]),\n",
    "         os.path.normpath(config[\"target_dir\"]),\n",
    "         config[\"hidden_size\"],\n",
    "         config[\"dropout\"],\n",
    "         config[\"num_classes\"],\n",
    "         config[\"epochs\"],\n",
    "         config[\"batch_size\"],\n",
    "         config[\"lr\"],\n",
    "         config[\"patience\"],\n",
    "         config[\"max_gradient_norm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model, dataloader):\n",
    "    \"\"\"\n",
    "    测试\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    time_start = time.time()\n",
    "    batch_time = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch_start = time.time()\n",
    "\n",
    "            premises = batch[\"premise\"].to(device)\n",
    "            premises_lengths = batch[\"premise_length\"].to(device)\n",
    "            hypotheses = batch[\"hypothesis\"].to(device)\n",
    "            hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            _, probs = model(premises,\n",
    "                             premises_lengths,\n",
    "                             hypotheses,\n",
    "                             hypotheses_lengths)\n",
    "\n",
    "            accuracy += correct_predictions(probs, labels)\n",
    "            batch_time += time.time() - batch_start\n",
    "\n",
    "    batch_time /= len(dataloader)\n",
    "    total_time = time.time() - time_start\n",
    "    accuracy /= (len(dataloader.dataset))\n",
    "\n",
    "    return batch_time, total_time, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在snli test数据集上进行测试\n",
    "def main2(test_file, pretrained_file, batch_size=32):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(30 * \"=\", \" Preparing for testing \", 30 * \"=\")\n",
    "\n",
    "    checkpoint = torch.load(pretrained_file)\n",
    "\n",
    "    vocab_size = checkpoint[\"model\"][\"_word_embedding.weight\"].size(0)\n",
    "    embedding_dim = checkpoint[\"model\"]['_word_embedding.weight'].size(1)\n",
    "    hidden_size = checkpoint[\"model\"][\"_projection.0.weight\"].size(0)\n",
    "    num_classes = checkpoint[\"model\"][\"_classification.4.weight\"].size(0)\n",
    "\n",
    "    print(\"\\t* Loading test data...\")\n",
    "    with open(test_file, \"rb\") as pkl:\n",
    "        test_data = NLIDataset(pickle.load(pkl))\n",
    "\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    print(\"\\t* Building model...\")\n",
    "    model = ESIM(vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_size,\n",
    "                 num_classes=num_classes,\n",
    "                 device=device).to(device)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "    print(30 * \"=\", \" Testing ESIM model on device: {} \".format(device),\n",
    "          30 * \"=\")\n",
    "    batch_time, total_time, accuracy = test(model, test_loader)\n",
    "\n",
    "    print(\"-> Average batch processing time: {:.4f}s, total test time:\\\n",
    " {:.4f}s, accuracy: {:.4f}%\".format(batch_time, total_time, (accuracy*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Preparing for testing  ====================\n",
      "\t* Loading test data...\n",
      "\t* Building model...\n",
      "==============================  Testing ESIM model on device: cuda:0  ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Average batch processing time: 0.0107s, total test time: 3.4015s, accuracy: 87.3371%\n"
     ]
    }
   ],
   "source": [
    "# load最优模型进行测试\n",
    "main2(\"data_task3/preprocessed/SNLI/test_data.pkl\",\n",
    "    \"data_task3/checkpoints/SNLI/best.pth.tar\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
